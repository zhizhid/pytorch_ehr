{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.cuda.set_device(0)\n",
    "import sys, random\n",
    "import numpy as np\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "from torch.nn._functions.thnn import rnnFusedPointwise as fusedBackend\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sl = pickle.load(open('pdata_3hosp/h143_train', 'rb'), encoding='bytes')\n",
    "valid_sl = pickle.load(open('pdata_3hosp/h143_valid', 'rb'), encoding='bytes')\n",
    "test_sl = pickle.load(open('pdata_3hosp/h143_test', 'rb'), encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TPLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(TPLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.weight_ih = Parameter(torch.Tensor(4 * hidden_size, input_size))\n",
    "        self.weight_hh = Parameter(torch.Tensor(4 * hidden_size, hidden_size))\n",
    "        self.W_decomp = Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        if bias:\n",
    "            self.bias_ih = Parameter(torch.Tensor(4 * hidden_size))\n",
    "            self.bias_hh = Parameter(torch.Tensor(4 * hidden_size))\n",
    "            self.b_decomp = Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        else:\n",
    "            self.register_parameter('bias_ih', None)\n",
    "            self.register_parameter('bias_hh', None)\n",
    "            self.register_parameter('b_decomp', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, hx):\n",
    "        print(input.size(),input.size()[0])\n",
    "        h=hx[0][0]\n",
    "        print (hx[0].size())\n",
    "        for i in range(input.size()[0]):\n",
    "            print (input[i].size(),h.size())\n",
    "            h,c = self.TPLSTMCell(input[i],hx,self.weight_ih, self.weight_hh,self.W_decomp,self.bias_ih, self.bias_hh,self.b_decomp)\n",
    "            hx=(h,c)\n",
    "            outputh.append(h)\n",
    "            outputc.append (c)\n",
    "        return outputh,(h,c),outputc\n",
    "    \n",
    "    def TPLSTMCell(self,input, hidden, w_ih, w_hh,w_decomp, b_ih=None, b_hh=None,b_decomp=None):\n",
    "        print (input.size(),input)\n",
    "        if input.is_cuda:\n",
    "            igates = F.linear(input, w_ih)\n",
    "            hgates = F.linear(hidden[0], w_hh)\n",
    "            state = fusedBackend.LSTMFused.apply\n",
    "            return state(igates, hgates, hidden[1]) if b_ih is None else state(igates, hgates, hidden[1], b_ih, b_hh)\n",
    "\n",
    "        hx, cx = hidden\n",
    "        \n",
    "        t= torch.transpose(input,0,1)[0]\n",
    "        print (t.size(),t)\n",
    "        ## Map elapse time in days or months\n",
    "        T = self.map_elapse_time(t) #----> need to define that\n",
    "\n",
    "        # Decompose the previous cell if there is a elapse time\n",
    "        C_ST = F.tanh(F.linear(cx, w_decomp, b_decomp) ) \n",
    "        C_ST_dis = torch.matmul(T, C_ST)\n",
    "            # if T is 0, then the weight is one\n",
    "\n",
    "        cpt = cx - C_ST + C_ST_dis\n",
    "        gates = F.linear(input, w_ih, b_ih) + F.linear(hx, w_hh, b_hh)\n",
    "\n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
    "\n",
    "        ingate = F.sigmoid(ingate)\n",
    "        forgetgate = F.sigmoid(forgetgate)\n",
    "        cellgate = F.tanh(cellgate)\n",
    "        outgate = F.sigmoid(outgate)\n",
    "            #C_ST = F.tanh(torch.mm(prev_cell, self.W_decomp) + self.b_decomp)  \n",
    "            #C_ST_dis = torch.mm(T, C_ST)\n",
    "            ## if T is 0, then the weight is one\n",
    "            #prev_cell = prev_cell - C_ST + C_ST_dis\n",
    "\n",
    "        #cy = (forgetgate * cx) + (ingate * cellgate)\n",
    "        ct = (forgetgate * cpt) + (ingate * cellgate)         ## Current Memory cell with time\n",
    "        ht = outgate * F.tanh(ct)\n",
    "\n",
    "        return ht, ct\n",
    "    \n",
    "    def map_elapse_time(self, t):\n",
    "\n",
    "        c1 = torch.Tensor([1.0])\n",
    "        c2 = torch.Tensor([2.7183])\n",
    "        T = torch.div(c1, torch.log(t + c2))#, name='Log_elapse_time')\n",
    "        Ones = torch.ones([1,self.hidden_size])\n",
    "        T = torch.matmul(T.view(-1,1), Ones)\n",
    "\n",
    "        return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EHR_TLSTM(nn.Module):\n",
    "    def __init__(self, input_size,embed_dim, hidden_size, n_layers=1,dropout_r=0.1,cell_type='TLSTM'):#,bi=False , preTrainEmb=''):\n",
    "        super(EHR_TLSTM,self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dropout_r = dropout_r\n",
    "        self.cell_type = cell_type\n",
    "        self.preTrainEmb=preTrainEmb=''\n",
    "        bi=False\n",
    "        if bi: self.bi=2 \n",
    "        else: self.bi=1\n",
    "              \n",
    "        if len(self.preTrainEmb)>0:\n",
    "            emb_t= torch.FloatTensor(np.asmatrix(self.preTrainEmb))\n",
    "            self.embed= nn.Embedding.from_pretrained(emb_t)#,freeze=False)  \n",
    "        else:\n",
    "            self.embed= nn.Embedding(input_size, self.embed_dim,padding_idx=0)\n",
    "        \n",
    "        if self.cell_type == \"GRU\":\n",
    "            cell = nn.GRU\n",
    "        elif self.cell_type == \"RNN\":\n",
    "            cell = nn.RNN\n",
    "        elif self.cell_type == \"LSTM\":\n",
    "            cell = nn.LSTM\n",
    "        elif self.cell_type == \"BNLSTM\":\n",
    "            cell = bnlstm.LSTM    \n",
    "        elif self.cell_type == \"TLSTM\":\n",
    "            cell = TPLSTM \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "      \n",
    "        if self.cell_type == \"BNLSTM\":\n",
    "            self.rnn_c = cell(bnlstm.BNLSTMCell, self.embed_dim, hidden_size,num_layers=n_layers,use_bias=False, dropout= dropout_r,max_length=30)\n",
    "        elif self.cell_type == \"TLSTM\":\n",
    "            self.bi=1 \n",
    "            #self.rnn_c = cell(self.embed_dim, 1, hidden_size, hidden_size/2)\n",
    "            self.rnn_c = cell(self.embed_dim, hidden_size)\n",
    "\n",
    "        else:\n",
    "            self.rnn_c = cell(self.embed_dim, hidden_size,num_layers=n_layers, dropout= dropout_r , bidirectional=bi  )\n",
    "        \n",
    "        self.out = nn.Linear(self.hidden_size*self.bi,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def EmbedPatient_MB(self, input): # x is a ehr_seq_tensor\n",
    "        \n",
    "        mb=[]\n",
    "        lbt=[]\n",
    "        seq_l=[]\n",
    "        self.bsize=len(input)\n",
    "        lp= len(max(input, key=lambda xmb: len(xmb[1]))[1])\n",
    "        self.max_len_bn=lp\n",
    "        #print (lp)\n",
    "        llv=0\n",
    "        for x in input:\n",
    "            lv= len(max(x[1], key=lambda xmb: len(xmb)))\n",
    "            if llv< lv:\n",
    "                llv=lv\n",
    "        #print (llv)\n",
    "        for pt in input:\n",
    "            label, ehr_seq_l = pt\n",
    "            lpx=len(ehr_seq_l)\n",
    "            seq_l.append(lpx)\n",
    "            label_tensor = Variable(torch.FloatTensor([[float(label)]]))\n",
    "            if use_cuda:\n",
    "                label_tensor = label_tensor.cuda()\n",
    "            lbt.append(label_tensor)\n",
    "            ml=(len(max(ehr_seq_l, key=len)))\n",
    "            ehr_seq_tl=[]\n",
    "            for ehr_seq in ehr_seq_l: \n",
    "                pd=(0, llv-len(ehr_seq))\n",
    "                result = F.pad(torch.from_numpy(np.asarray(ehr_seq,dtype=int)).type(torch.LongTensor),pd,\"constant\", 0)\n",
    "                if use_cuda:\n",
    "                    result.cuda()\n",
    "                ehr_seq_tl.append(result)\n",
    "            ehr_seq_t= Variable(torch.stack(ehr_seq_tl,0))     \n",
    "            lpp= lp-lpx\n",
    "            zp= nn.ZeroPad2d((0,0,lpp,0))\n",
    "            ehr_seq_t= zp(ehr_seq_t)\n",
    "            mb.append(ehr_seq_t)\n",
    "                \n",
    "        mb_t= Variable(torch.stack(mb,0)) \n",
    "        if use_cuda:\n",
    "            mb_t.cuda()\n",
    "        embedded = self.embed(mb_t)\n",
    "        embedded = torch.sum(embedded, dim=2) \n",
    "        lbt_t= Variable(torch.stack(lbt,0)) \n",
    "        return embedded, lbt_t,seq_l\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        h_0 = Variable(torch.rand(self.n_layers*self.bi,self.bsize, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            h_0= h_0.cuda()\n",
    "        if self.cell_type == \"LSTM\"or self.cell_type == \"TLSTM\":\n",
    "            result = (h_0,h_0)\n",
    "        else: \n",
    "            result = h_0\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        x_in , lt ,x_lens = self.EmbedPatient_MB(input)\n",
    "        x_in = x_in.permute(1,0,2) ## QRNN not support batch first\n",
    "        #x_inp = nn.utils.rnn.pack_padded_sequence(x_in,x_lens,batch_first=True)\n",
    "        h_0 = self.init_hidden()\n",
    "        output, hidden,_ = self.rnn_c(x_in,h_0) \n",
    "        if self.cell_type == \"LSTM\" or self.cell_type == \"TLSTM\":\n",
    "            hidden=hidden[0]\n",
    "        if self.bi==2:\n",
    "            output = self.sigmoid(self.out(torch.cat((hidden[-2],hidden[-1]),1)))\n",
    "        #elif self.cell_type == \"TLSTM\":\n",
    "            #output = hidden\n",
    "        else:\n",
    "            output = self.sigmoid(self.out(hidden[-1]))\n",
    "        return output.squeeze(), lt.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EHR_TLSTM(input_size=16000, hidden_size=128 ,embed_dim=128, dropout_r=0, cell_type='TLSTM', n_layers=1)\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (tmodel,mini_batch, criterion, optimizer):  \n",
    "    \n",
    "    tmodel.train()\n",
    "    tmodel.zero_grad()\n",
    "    output , label_tensor = tmodel(mini_batch)\n",
    "    loss = criterion(output, label_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "   \n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training all samples in random order\n",
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_train(tmodel,dataset,batch_size,learning_rate = 0.01, l2=1e-04,epsl=1e-06 ):\n",
    "    \n",
    "    #optimizer = optim.SGD(tmodel.parameters(), lr=learning_rate)#, weight_decay=l2)\n",
    "    #optimizer = optim.Adadelta(tmodel.parameters(), lr=learning_rate, weight_decay=l2)\n",
    "    #optimizer = optim.ASGD(tmodel.parameters(), lr=learning_rate, weight_decay=l2 )\n",
    "    #optimizer = optim.SparseAdam (tmodel.parameters(),lr=learning_rate) #'''lr=learning_rate,''' \n",
    "    optimizer = optim.Adagrad (tmodel.parameters(),lr=learning_rate, weight_decay=l2) #'''lr=learning_rate,''' \n",
    "    #optimizer = optim.Adamax(tmodel.parameters(), lr=learning_rate, weight_decay=l2 ,eps=epsl)\n",
    "    #optimizer = optim.Adamax(filter(lambda p: p.requires_grad, tmodel.parameters()), lr=learning_rate, weight_decay=l2 ,eps=epsl) ### Beta defaults (0.9, 0.999)\n",
    "    #optimizer = optim.RMSprop (tmodel.parameters(),lr=learning_rate, weight_decay=l2 ,eps=epsl)\n",
    "    #optimizer = optim.Adam(tmodel.parameters(), lr=learning_rate, weight_decay=learning_rate)\n",
    "    dataset.sort(key=lambda pt:len(pt[1]),reverse=True) \n",
    "    # Keep track of losses for plotting\n",
    "    current_loss = 0\n",
    "    all_losses = []\n",
    "    print_every = 10#int(batch_size/2)\n",
    "    plot_every = 5\n",
    "    iter=0\n",
    "    n_batches = int(np.ceil(int(len(dataset)) / int(batch_size)))\n",
    "    start = time.time()\n",
    "\n",
    "    for index in random.sample(range(n_batches), n_batches):\n",
    "            batch = dataset[index*batch_size:(index+1)*batch_size]\n",
    "            output, loss = train(tmodel,batch, criterion = nn.BCELoss(), optimizer = optimizer)\n",
    "            current_loss += loss\n",
    "            iter +=1\n",
    "            # Add current loss avg to list of losses\n",
    "            if iter % plot_every == 0:\n",
    "                all_losses.append(current_loss / plot_every)\n",
    "                current_loss = 0\n",
    "                \n",
    "    return current_loss,all_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_auc(test_model, dataset, batch_size=200):\n",
    "    test_model.eval()\n",
    "    dataset.sort(key=lambda pt:len(pt[1]),reverse=True) \n",
    "    n_batches = int(np.ceil(int(len(dataset)) / int(batch_size)))\n",
    "    labelVec =[]\n",
    "    y_hat= []\n",
    "    \n",
    "    for index in range(n_batches):\n",
    "            batch = dataset[index*batch_size:(index+1)*batch_size]\n",
    "            output, label_t = test_model(batch)\n",
    "            y_hat.extend(output.cpu().data.view(-1).numpy())\n",
    "            labelVec.extend(label_t.cpu().data.view(-1).numpy())\n",
    "    auc = roc_auc_score(labelVec, y_hat)\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 128, 128]) 23\n",
      "torch.Size([1, 128, 128])\n",
      "torch.Size([128, 128]) torch.Size([128, 128])\n",
      "torch.Size([128, 128]) tensor([[  2.4297,   1.9933,   2.3835,  ...,   6.7208,   8.4321,\n",
      "           2.3511],\n",
      "        [ -2.9820,  -1.8596,   2.6445,  ...,  -0.2735,  -0.3324,\n",
      "           4.2808],\n",
      "        [ -0.3485,   7.9159,  -1.8496,  ...,  -0.5786,  10.6515,\n",
      "          -7.4925],\n",
      "        ...,\n",
      "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,\n",
      "           0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,\n",
      "           0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,\n",
      "           0.0000]])\n",
      "torch.Size([128]) tensor([ 2.4297, -2.9820, -0.3485,  1.0450,  1.3424,  0.9203,  4.0133,\n",
      "        -0.1782, -0.2402,  4.1936, -1.6323,  0.6919, -7.0909,  0.2668,\n",
      "         4.6437,  2.2095,  2.7666,  1.5604, -0.6815, -0.3371,  0.5597,\n",
      "         1.8969,  0.1123, -3.0449,  2.9321, -2.7553, -0.2724,  2.3463,\n",
      "         3.4177,  0.6882, -0.4719, -1.5298, -0.6978, -2.0222, -0.3124,\n",
      "         0.4582,  3.5243, -5.0203,  0.1535,  2.2052,  0.6266,  0.3049,\n",
      "         1.0618, -0.6440, -1.3055, -0.3310,  1.0340, -1.4047,  1.3096,\n",
      "         4.0608,  1.8036,  0.8375, -2.6807,  1.1985,  0.7628,  1.6948,\n",
      "         2.5511,  2.1898,  2.9125, -1.1268, -1.4071,  1.4932,  2.7864,\n",
      "         2.2000,  0.5597,  4.1901, -0.3931, -1.2400,  0.3074,  1.0202,\n",
      "         1.2259,  0.5398,  0.9252, -0.1177, -0.6274, -2.4715, -2.0250,\n",
      "        -1.8571,  1.8694,  5.5467,  2.4314, -0.7992, -3.8609, -0.3883,\n",
      "         0.6041,  2.1878, -1.0714, -2.8686,  0.0525,  1.3001, -1.0810,\n",
      "         2.4539,  6.6244,  1.1426,  0.1579, -0.0301, -0.7389, -0.7547,\n",
      "        -0.4711, -1.8092,  3.1231, -2.0401,  2.8717, -2.2173,  5.7600,\n",
      "        -5.6117, -0.1434, -0.7474, -8.2216,  1.5564,  0.2937,  0.9131,\n",
      "         0.7294,  2.6465,  1.2724,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (512) must match the size of tensor b (128) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-286-2cb09d4c32dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#print (model.embed.weight.data[135] )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mcurrent_loss_la\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_losses_la\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_sl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeSince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0meval_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-284-42ac5d291c50>\u001b[0m in \u001b[0;36mrun_model_train\u001b[0;34m(tmodel, dataset, batch_size, learning_rate, l2, epsl)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0miter\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-282-a9e788e5c0ff>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(tmodel, mini_batch, criterion, optimizer)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-280-760ed4798568>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m#x_inp = nn.utils.rnn.pack_padded_sequence(x_in,x_lens,batch_first=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mh_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"LSTM\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"TLSTM\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-279-eb77ecc264ee>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_decomp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_decomp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mhx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moutputh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-279-eb77ecc264ee>\u001b[0m in \u001b[0;36mTPLSTMCell\u001b[0;34m(self, input, hidden, w_ih, w_hh, w_decomp, b_ih, b_hh, b_decomp)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m#cy = (forgetgate * cx) + (ingate * cellgate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforgetgate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcpt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mingate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m## Current Memory cell with time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mht\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (128) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "epochs=100\n",
    "batch_size=128\n",
    "current_loss_l=[]\n",
    "all_losses_l=[]\n",
    "train_auc_allep =[]\n",
    "valid_auc_allep =[]\n",
    "test_auc_allep=[]\n",
    "bestValidAuc = 0.0\n",
    "bestTestAuc = 0.0\n",
    "bestValidEpoch = 0\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "### Run Epochs    \n",
    "for ep in range(epochs):\n",
    "    \n",
    "    #print (model.embed.weight.data[135] )\n",
    "    start = time.time()\n",
    "    current_loss_la,all_losses_la = run_model_train(model,train_sl,batch_size)\n",
    "    train_time = timeSince(start)\n",
    "    eval_start = time.time()\n",
    "    train_auc = calculate_auc(model,train_sl,batch_size)\n",
    "    test_auc = calculate_auc(model,test_sl,batch_size)\n",
    "    valid_auc = calculate_auc(model,valid_sl,batch_size)\n",
    "    eval_time = timeSince(eval_start)\n",
    "    all_losses_l.append (all_losses_la)\n",
    "    avg_loss = np.mean(all_losses_la)\n",
    "    train_auc_allep.append(train_auc)\n",
    "    valid_auc_allep.append(valid_auc)\n",
    "    test_auc_allep.append(test_auc)\n",
    "    current_loss_l.append(current_loss_la)\n",
    "    print (\"Epoch \", ep,\" Train_auc :\", train_auc, \" , Valid_auc : \", valid_auc, \" ,& Test_auc : \" , test_auc,\" Avg Loss: \", avg_loss, 'Train Time (%s) Eval Time (%s)'%(train_time,eval_time) )\n",
    "     \n",
    "    if valid_auc > bestValidAuc: \n",
    "        bestValidAuc = valid_auc\n",
    "        bestValidEpoch = ep\n",
    "        bestTestAuc = test_auc\n",
    "        best_model = model\n",
    "        torch.save(best_model, bmodel_pth)\n",
    "        torch.save(best_model.state_dict(), bmodel_st)\n",
    "    if ep - bestValidEpoch >12: break\n",
    "            \n",
    "print ('bestValidAuc %f has a TestAuc of %f at epoch %d ' % (bestValidAuc, bestTestAuc, bestValidEpoch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
